{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 00 OpenAI API KEY 로드하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "\n",
    "with open('conf.json', 'r') as f:\n",
    "    json_data = json.load(f)\n",
    "    \n",
    "os.environ['OPENAI_API_KEY'] = json_data['openai_config']['API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01 모든 ETF의 심볼과 구성종목들의 심볼 로드하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.fetch_data import fetch_data_from_db\n",
    "import pandas as pd\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT pdf.etf_tkr, pdf.child_stk_tkr\n",
    "        FROM os_pdf_info pdf\n",
    "        INNER JOIN os_stk_info stk\n",
    "        ON pdf.child_stk_tkr=stk.stk_tkr\n",
    "\"\"\"\n",
    "\n",
    "ticker_df = pd.DataFrame(fetch_data_from_db(query=query)) \n",
    "\n",
    "ticker_list = list(set(ticker_df['child_stk_tkr'].to_list()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02 yfinance에서 개별 주식들의 metadata와 사업개요 로드하기\n",
    "- 테스트 속도 향상을 위해 23-09-11 일자 뉴스 데이터로 실행합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c15978024eb64f5b8ea43640d808adb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/712 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "yf_stk_info = yf.Tickers(\" \".join(ticker_list))\n",
    "\n",
    "for t in tqdm(ticker_list):\n",
    "    \n",
    "    # 이미 뉴스가 존재하면 패스합니다. \n",
    "    if os.path.isfile(f\"./stk_infos/{t}.json\"):\n",
    "        continue\n",
    "\n",
    "    parent_etfs = ticker_df[ticker_df['child_stk_tkr']==t]['etf_tkr'].to_list()\n",
    "\n",
    "    yf_stk_info.tickers[t].info['parent_etfs'] = parent_etfs\n",
    "    \n",
    "    if \"longBusinessSummary\" not in yf_stk_info.tickers[t].info.keys():\n",
    "        print(t)\n",
    "        yf_stk_info.tickers[t].info[\"longBusinessSummary\"] = \"None\"\n",
    "\n",
    "    with open(f'./stk_infos/{t}.json', 'w') as f:\n",
    "        json.dump(yf_stk_info.tickers[t].info, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import JSONLoader\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "\n",
    "def metadata_func(record: dict, metadata: dict) -> dict:\n",
    "        \n",
    "    for k, v in record.items():\n",
    "        if k=='longBusinessSummary':\n",
    "            continue\n",
    "        \n",
    "        if k == 'parent_etfs':\n",
    "            metadata[k] = \",\".join(record.get(k))\n",
    "        \n",
    "        if type(record.get(k)) not in [str, int, float]:\n",
    "            continue\n",
    "        \n",
    "        metadata[k] = record.get(k)\n",
    "\n",
    "    return metadata\n",
    "\n",
    "loader = DirectoryLoader('./stk_infos',\n",
    "                         glob='*.json', \n",
    "                         loader_cls=JSONLoader, \n",
    "                         loader_kwargs={'jq_schema': '.',\n",
    "                                        'content_key': 'longBusinessSummary',\n",
    "                                        'metadata_func': metadata_func})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "712"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = loader.load()\n",
    "\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "# text_splitter = RecursiveCharacterTextSplitter(chunk_size=10000, chunk_overlap=200) #10000자 씩 끊되, 200자 씩 겹치게 만든다.\n",
    "# texts = text_splitter.split_documents(documents)\n",
    "\n",
    "# print(len(texts))\n",
    "\n",
    "# persist_directory='db'\n",
    "\n",
    "# embedding = OpenAIEmbeddings(\n",
    "#     model='text-embedding-ada-002'\n",
    "# )\n",
    "\n",
    "# vectordb = Chroma.from_documents(\n",
    "#     documents=texts,\n",
    "#     embedding=embedding,\n",
    "#     persist_directory=persist_directory,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03 유사도 검색을 할 Keyword 산출하기\n",
    "- 33개 ETF의 추종 지수 methology book에 기재되어있는 subcategory를 입력하였습니다(수동)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "키워드: This category includes companies that develop AI and use AI in their own products. Companies that have developed internal AI capabilities (organically or through acquisition) and are applying artificial intelligence technology to enhance their products and services are the focus. AI applications include but are not limited to language/image processing and recognition, automated communications, threat detection, recommendation generation, and other predictive analytics. The companies are considered for inclusion in this category based on the level of AI involvement of the companies.\n",
      "\n",
      "키워드와 사업개요가 가장 유사한 기업들: ['INFA', 'INTC', 'ACN', 'IBM', 'CGNX']\n",
      "\n",
      "====================================================================================================\n",
      "키워드: Companies that provide artificial intelligence capabilities to their customers as a service. Companies in this segment typically offer cloud-based platforms that allow their customers to apply artificial intelligence techniques without needing to make a direct investment in AI-related infrastructure.\n",
      "\n",
      "키워드와 사업개요가 가장 유사한 기업들: ['INFA', 'IBM', 'ACN', 'NOW', 'CCCS']\n",
      "\n",
      "====================================================================================================\n",
      "키워드: Companies that produce semiconductors, memory storage and other hardware that is utilized for artificial intelligence applications.\n",
      "\n",
      "키워드와 사업개요가 가장 유사한 기업들: ['INTC', 'INFA', 'AMBA', 'IONQ', 'NVDA']\n",
      "\n",
      "====================================================================================================\n",
      "키워드: Companies that are at the forefront of developing quantum computing technology, which is in the process of being commercialized and is expected to have significance in AI and big data applications in the future.\n",
      "\n",
      "키워드와 사업개요가 가장 유사한 기업들: ['IONQ', 'INFA', 'INTC', 'QCOM', 'IBM']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from core.gpt_semantic_search import get_vectordb, get_filter, get_similar_symbols\n",
    "\n",
    "class CONFIG:\n",
    "    etf_tkr=\"AIQ\"\n",
    "\n",
    "filter_list = get_filter(etf_tkr=CONFIG.etf_tkr)\n",
    "\n",
    "with open(f'subcategory_infos/{CONFIG.etf_tkr}.json', 'r') as f:\n",
    "    json_data = json.load(f)\n",
    "    \n",
    "vectordb = get_vectordb()\n",
    "    \n",
    "docs_list = vectordb.get(where={'$or': filter_list})\n",
    "\n",
    "for i, subcategory in enumerate(json_data['subcategory_lists']):\n",
    "    \n",
    "    keyword = subcategory['description']\n",
    "    \n",
    "    similar_stk_list = get_similar_symbols( \n",
    "            vectordb=vectordb,\n",
    "            keyword=keyword,\n",
    "            filter_list=filter_list,\n",
    "            k=5,\n",
    "        )\n",
    "    \n",
    "    print(\"=\"*100)\n",
    "    \n",
    "    print(\"키워드:\", keyword)\n",
    "    print()\n",
    "    \n",
    "    print(\"키워드와 사업개요가 가장 유사한 기업들:\", similar_stk_list)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.20179798, 'BIDU')\n",
      "(0.2626706, 'STNE')\n",
      "(0.49416146, 'BZ')\n",
      "(0.49793226, 'VSAT')\n",
      "(1.0785595, 'HPE')\n",
      "(1.1891185, 'TWLO')\n",
      "(1.320185, 'DXC')\n",
      "(1.5749, 'ERIC')\n",
      "(1.5758052, 'INTC')\n",
      "(1.8860711, 'VRNT')\n",
      "(2.541446, 'OKTA')\n",
      "====================================================================================================\n",
      "(97.82, 'NVDA')\n",
      "(86.2, 'META')\n",
      "(72.97, 'ORCL')\n",
      "(70.11, 'TTD')\n",
      "(68.37, 'SNPS')\n",
      "(68.27, 'AMZN')\n",
      "(65.45, 'AAPL')\n",
      "(64.26, 'CDNS')\n",
      "(63.33, 'UBER')\n",
      "(60.59, 'GOOGL')\n",
      "(57.99, 'IONQ')\n",
      "(54.55, 'CRM')\n"
     ]
    }
   ],
   "source": [
    "from core.financial_filtering import get_lowest_PBR_stks, get_momentums\n",
    "\n",
    "docs_list = vectordb.get(where={'$or': filter_list})\n",
    "\n",
    "lowest_PBR_stks_tuple_list = get_lowest_PBR_stks(docs_list=docs_list)\n",
    "\n",
    "momentum_tuple_list = get_momentums(filter_list=filter_list)\n",
    "\n",
    "for stk_pbr in lowest_PBR_stks_tuple_list:\n",
    "    print(stk_pbr)\n",
    "\n",
    "print(\"=\"*100)\n",
    "\n",
    "for stk_mmt in momentum_tuple_list:\n",
    "    print(stk_mmt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
